{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdaef392",
   "metadata": {},
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"import numpy as np\\n\",\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"import matplotlib.pyplot as plt\\n\",\n",
    "    \"import seaborn as sns\\n\",\n",
    "    \"import joblib\\n\",\n",
    "    \"from pathlib import Path\\n\",\n",
    "    \"from sklearn.feature_selection import SelectKBest, f_classif\\n\",\n",
    "    \"from sklearn.model_selection import train_test_split\\n\",\n",
    "    \"from xgboost import XGBClassifier\\n\",\n",
    "    \"from sklearn.metrics import roc_curve, auc\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Set up paths\\n\",\n",
    "    \"Path('./outputs/figures').mkdir(parents=True, exist_ok=True)\\n\",\n",
    "    \"Path('./outputs/models').mkdir(parents=True, exist_ok=True)\\n\",\n",
    "    \"Path('./outputs/data').mkdir(parents=True, exist_ok=True)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Load or recreate data\\n\",\n",
    "    \"def load_or_create_data():\\n\",\n",
    "    \"    try:\\n\",\n",
    "    \"        X = np.load('./outputs/data/X_test.npy')\\n\",\n",
    "    \"        y = np.load('./outputs/data/y_test.npy')\\n\",\n",
    "    \"        print(\\\"Loaded existing test data\\\")\\n\",\n",
    "    \"        return X, y\\n\",\n",
    "    \"    except:\\n\",\n",
    "    \"        print(\\\"Creating new test data\\\")\\n\",\n",
    "    \"        # Load original data\\n\",\n",
    "    \"        df = pd.read_csv('./data/higgs_sample.csv', header=None)\\n\",\n",
    "    \"        X = df.iloc[:, 1:].values\\n\",\n",
    "    \"        y = df.iloc[:, 0].values\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Simple preprocessing\\n\",\n",
    "    \"        from sklearn.preprocessing import MinMaxScaler\\n\",\n",
    "    \"        scaler = MinMaxScaler()\\n\",\n",
    "    \"        X = scaler.fit_transform(X)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Split data\\n\",\n",
    "    \"        X_train, X_test, y_train, y_test = train_test_split(\\n\",\n",
    "    \"            X, y, test_size=0.2, random_state=42, stratify=y\\n\",\n",
    "    \"        )\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Save test data\\n\",\n",
    "    \"        np.save('./outputs/data/X_test.npy', X_test)\\n\",\n",
    "    \"        np.save('./outputs/data/y_test.npy', y_test)\\n\",\n",
    "    \"        return X_test, y_test\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Visualization functions\\n\",\n",
    "    \"def generate_roc_comparison(models, X_test, y_test):\\n\",\n",
    "    \"    plt.figure(figsize=(10, 8))\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    for name, model in models.items():\\n\",\n",
    "    \"        if hasattr(model, \\\"predict_proba\\\"):\\n\",\n",
    "    \"            y_proba = model.predict_proba(X_test)[:, 1]\\n\",\n",
    "    \"        else:  # Handle SVM\\n\",\n",
    "    \"            decision = model.decision_function(X_test)\\n\",\n",
    "    \"            y_proba = (decision - decision.min()) / (decision.max() - decision.min())\\n\",\n",
    "    \"            \\n\",\n",
    "    \"        fpr, tpr, _ = roc_curve(y_test, y_proba)\\n\",\n",
    "    \"        roc_auc = auc(fpr, tpr)\\n\",\n",
    "    \"        plt.plot(fpr, tpr, lw=2.5, label=f'{name} (AUC = {roc_auc:.3f})')\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    plt.plot([0, 1], [0, 1], 'k--', lw=2)\\n\",\n",
    "    \"    plt.xlabel('False Positive Rate', fontsize=12, weight='bold')\\n\",\n",
    "    \"    plt.ylabel('True Positive Rate', fontsize=12, weight='bold')\\n\",\n",
    "    \"    plt.title('ROC Curve Comparison', fontsize=14, weight='bold')\\n\",\n",
    "    \"    plt.legend(loc=\\\"lower right\\\", fontsize=10)\\n\",\n",
    "    \"    plt.grid(True, alpha=0.3)\\n\",\n",
    "    \"    plt.savefig('./outputs/figures/roc_comparison.png', dpi=300, bbox_inches='tight')\\n\",\n",
    "    \"    plt.close()\\n\",\n",
    "    \"    print(\\\"Generated ROC comparison\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"def plot_anova_feature_importance(X, y, feature_names):\\n\",\n",
    "    \"    \\\"\\\"\\\"Calculate and plot ANOVA F-scores\\\"\\\"\\\"\\n\",\n",
    "    \"    selector = SelectKBest(score_func=f_classif, k=15)\\n\",\n",
    "    \"    selector.fit(X, y)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    plt.figure(figsize=(12, 8))\\n\",\n",
    "    \"    scores = selector.scores_\\n\",\n",
    "    \"    sorted_idx = scores.argsort()[::-1]\\n\",\n",
    "    \"    sorted_scores = scores[sorted_idx][:20]\\n\",\n",
    "    \"    sorted_features = [feature_names[i] for i in sorted_idx][:20]\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    plt.barh(sorted_features, sorted_scores, color='#3498db', height=0.7)\\n\",\n",
    "    \"    plt.xlabel('F-Score', fontsize=12, weight='bold')\\n\",\n",
    "    \"    plt.ylabel('Features', fontsize=12, weight='bold')\\n\",\n",
    "    \"    plt.title('Top 20 Features by ANOVA F-Score', fontsize=14, weight='bold')\\n\",\n",
    "    \"    plt.gca().invert_yaxis()\\n\",\n",
    "    \"    plt.grid(axis='x', alpha=0.3)\\n\",\n",
    "    \"    plt.savefig('./outputs/figures/feature_importance.png', dpi=300, bbox_inches='tight')\\n\",\n",
    "    \"    plt.close()\\n\",\n",
    "    \"    print(\\\"Generated ANOVA feature importance\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Save selector for later use\\n\",\n",
    "    \"    joblib.dump(selector, './outputs/feature_selector.pkl')\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"def plot_xgb_feature_importance(model, feature_names):\\n\",\n",
    "    \"    \\\"\\\"\\\"Plot XGBoost feature importance\\\"\\\"\\\"\\n\",\n",
    "    \"    plt.figure(figsize=(12, 8))\\n\",\n",
    "    \"    importance = model.feature_importances_\\n\",\n",
    "    \"    sorted_idx = importance.argsort()[::-1]\\n\",\n",
    "    \"    sorted_imp = importance[sorted_idx][:15]\\n\",\n",
    "    \"    sorted_features = [feature_names[i] for i in sorted_idx][:15]\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    plt.barh(sorted_features, sorted_imp, color='#e74c3c', height=0.7)\\n\",\n",
    "    \"    plt.xlabel('Importance Score', fontsize=12, weight='bold')\\n\",\n",
    "    \"    plt.ylabel('Features', fontsize=12, weight='bold')\\n\",\n",
    "    \"    plt.title('XGBoost Feature Importance', fontsize=14, weight='bold')\\n\",\n",
    "    \"    plt.gca().invert_yaxis()\\n\",\n",
    "    \"    plt.grid(axis='x', alpha=0.3)\\n\",\n",
    "    \"    plt.savefig('./outputs/figures/xgboost_feature_importance.png', dpi=300, bbox_inches='tight')\\n\",\n",
    "    \"    plt.close()\\n\",\n",
    "    \"    print(\\\"Generated XGBoost feature importance\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Main execution\\n\",\n",
    "    \"def main():\\n\",\n",
    "    \"    # Load or create data\\n\",\n",
    "    \"    X_test, y_test = load_or_create_data()\\n\",\n",
    "    \"    feature_names = [f'feature_{i}' for i in range(1, 29)]\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Generate feature importance plot\\n\",\n",
    "    \"    plot_anova_feature_importance(X_test, y_test, feature_names)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Train a simple XGBoost model if needed\\n\",\n",
    "    \"    if not Path('./outputs/models/XGBoost.pkl').exists():\\n\",\n",
    "    \"        print(\\\"Training XGBoost model...\\\")\\n\",\n",
    "    \"        xgb_model = XGBClassifier(\\n\",\n",
    "    \"            n_estimators=100,\\n\",\n",
    "    \"            max_depth=5,\\n\",\n",
    "    \"            learning_rate=0.1,\\n\",\n",
    "    \"            random_state=42,\\n\",\n",
    "    \"            use_label_encoder=False,\\n\",\n",
    "    \"            eval_metric='logloss'\\n\",\n",
    "    \"        )\\n\",\n",
    "    \"        xgb_model.fit(X_test, y_test)  # Note: Using test data just for visualization\\n\",\n",
    "    \"        joblib.dump(xgb_model, './outputs/models/XGBoost.pkl')\\n\",\n",
    "    \"    else:\\n\",\n",
    "    \"        xgb_model = joblib.load('./outputs/models/XGBoost.pkl')\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Generate XGBoost feature importance\\n\",\n",
    "    \"    plot_xgb_feature_importance(xgb_model, feature_names)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Create model dictionary for ROC comparison\\n\",\n",
    "    \"    models = {\\n\",\n",
    "    \"        'XGBoost': xgb_model\\n\",\n",
    "    \"    }\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Generate ROC comparison\\n\",\n",
    "    \"    generate_roc_comparison(models, X_test, y_test)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    print(\\\"\\\\nAll visualizations generated successfully!\\\")\\n\",\n",
    "    \"    print(\\\"Check the outputs/figures directory for your plots.\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"if __name__ == \\\"__main__\\\":\\n\",\n",
    "    \"    main()\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"higgs-env\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.11.5\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 2\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
