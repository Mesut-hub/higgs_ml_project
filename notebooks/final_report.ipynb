{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98a4e923",
   "metadata": {},
   "source": [
    "# higgs-ml-project/notebooks/final_report.ipynb\n",
    "\n",
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Machine Learning Pipeline: Feature Selection and Hyperparameter Optimization\\n\",\n",
    "    \"## Üsküdar Üniversitesi Fen Bilimleri Enstitüsü\\n\",\n",
    "    \"### Makine Öğrenmesi Final Ödevi\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 1. Giriş ve Veri Seti Tanıtımı\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Import libraries\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"import matplotlib.pyplot as plt\\n\",\n",
    "    \"import seaborn as sns\\n\",\n",
    "    \"from sklearn.model_selection import train_test_split\\n\",\n",
    "    \"from pathlib import Path\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Set global styles\\n\",\n",
    "    \"plt.style.use('ggplot')\\n\",\n",
    "    \"sns.set_palette('viridis')\\n\",\n",
    "    \"pd.set_option('display.float_format', '{:.4f}'.format)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Load the data\\n\",\n",
    "    \"data_path = Path('../data/higgs_sample.csv')\\n\",\n",
    "    \"df = pd.read_csv(data_path, header=None)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Name columns according to HIGGS dataset documentation\\n\",\n",
    "    \"columns = ['class_label'] + [f'feature_{i}' for i in range(1, 29)]\\n\",\n",
    "    \"df.columns = columns\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Display dataset info\\n\",\n",
    "    \"print(f\\\"Dataset shape: {df.shape}\\\")\\n\",\n",
    "    \"print(\\\"\\\\nFirst 5 rows:\\\")\\n\",\n",
    "    \"display(df.head())\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Class distribution\\n\",\n",
    "    \"class_dist = df['class_label'].value_counts(normalize=True)\\n\",\n",
    "    \"print(\\\"\\\\nClass distribution:\\\")\\n\",\n",
    "    \"display(class_dist)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 2. Veri Ön İşleme\\n\",\n",
    "    \"### Aykırı Değer Analizi ve Ölçekleme\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"from src.preprocessing import OutlierCapper\\n\",\n",
    "    \"from sklearn.preprocessing import MinMaxScaler\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Separate features and target\\n\",\n",
    "    \"X = df.drop('class_label', axis=1)\\n\",\n",
    "    \"y = df['class_label']\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Outlier handling\\n\",\n",
    "    \"capper = OutlierCapper(factor=1.5)\\n\",\n",
    "    \"X_capped = pd.DataFrame(capper.fit_transform(X), columns=X.columns)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Visualize before/after for sample features\\n\",\n",
    "    \"fig, axes = plt.subplots(2, 2, figsize=(12, 8))\\n\",\n",
    "    \"sns.boxplot(data=X[['feature_1', 'feature_2']], ax=axes[0, 0])\\n\",\n",
    "    \"axes[0, 0].set_title('Original Features (Sample)')\\n\",\n",
    "    \"\\n\",\n",
    "    \"sns.boxplot(data=X_capped[['feature_1', 'feature_2']], ax=axes[0, 1])\\n\",\n",
    "    \"axes[0, 1].set_title('After Outlier Capping (Sample)')\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Scaling\\n\",\n",
    "    \"scaler = MinMaxScaler()\\n\",\n",
    "    \"X_scaled = pd.DataFrame(scaler.fit_transform(X_capped), columns=X.columns)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Visualize scaling results\\n\",\n",
    "    \"sns.histplot(X_scaled['feature_1'], kde=True, ax=axes[1, 0])\\n\",\n",
    "    \"axes[1, 0].set_title('Scaled Feature 1 Distribution')\\n\",\n",
    "    \"\\n\",\n",
    "    \"sns.histplot(X_scaled['feature_2'], kde=True, ax=axes[1, 1])\\n\",\n",
    "    \"axes[1, 1].set_title('Scaled Feature 2 Distribution')\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.savefig('../outputs/figures/preprocessing_results.png', dpi=300)\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 3. Özellik Seçimi\\n\",\n",
    "    \"### ANOVA F-Skor ile En Önemli 15 Özelliğin Seçimi\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"from src.feature_selection import select_features\\n\",\n",
    "    \"from sklearn.feature_selection import f_classif\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Feature selection\\n\",\n",
    "    \"X_selected, selected_idx = select_features(X_scaled.values, y.values, method='anova', k=15)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Get selected feature names\\n\",\n",
    "    \"selected_features = X_scaled.columns[selected_idx].tolist()\\n\",\n",
    "    \"print(f\\\"Selected {len(selected_features)} features:\\\")\\n\",\n",
    "    \"print(selected_features)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Calculate ANOVA F-scores for all features\\n\",\n",
    "    \"f_scores, _ = f_classif(X_scaled, y)\\n\",\n",
    "    \"feature_scores = pd.DataFrame({\\n\",\n",
    "    \"    'Feature': X_scaled.columns,\\n\",\n",
    "    \"    'F_Score': f_scores\\n\",\n",
    "    \"}).sort_values('F_Score', ascending=False)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Visualize feature importance\\n\",\n",
    "    \"plt.figure(figsize=(12, 8))\\n\",\n",
    "    \"sns.barplot(x='F_Score', y='Feature', data=feature_scores.head(20))\\n\",\n",
    "    \"plt.title('Top 20 Features by ANOVA F-Score')\\n\",\n",
    "    \"plt.xlabel('F-Score')\\n\",\n",
    "    \"plt.ylabel('Feature')\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.savefig('../outputs/figures/feature_importance.png', dpi=300)\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 4. Modelleme ve Değerlendirme\\n\",\n",
    "    \"### İç İçe Çapraz Doğrulama (Nested Cross-Validation) ile Model Performansı\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"import joblib\\n\",\n",
    "    \"from src.modeling import get_models\\n\",\n",
    "    \"from src.evaluation import evaluate_model\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Load pre-trained models and results\\n\",\n",
    "    \"model_results = {}\\n\",\n",
    "    \"models = get_models()\\n\",\n",
    "    \"\\n\",\n",
    "    \"for model_name in models.keys():\\n\",\n",
    "    \"    try:\\n\",\n",
    "    \"        # Load metrics\\n\",\n",
    "    \"        metrics_path = f'../outputs/results/{model_name}_metrics.csv'\\n\",\n",
    "    \"        metrics_df = pd.read_csv(metrics_path)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Load best model from first fold\\n\",\n",
    "    \"        model_path = f'../outputs/models/{model_name}_fold1.pkl'\\n\",\n",
    "    \"        model = joblib.load(model_path)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        model_results[model_name] = {\\n\",\n",
    "    \"            'metrics': metrics_df,\\n\",\n",
    "    \"            'model': model\\n\",\n",
    "    \"        }\\n\",\n",
    "    \"        print(f\\\"Loaded results for {model_name}\\\")\\n\",\n",
    "    \"    except FileNotFoundError:\\n\",\n",
    "    \"        print(f\\\"Results not found for {model_name}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Calculate average metrics\\n\",\n",
    "    \"performance_summary = []\\n\",\n",
    "    \"for model_name, data in model_results.items():\\n\",\n",
    "    \"    avg_metrics = data['metrics'].mean().to_dict()\\n\",\n",
    "    \"    avg_metrics['Model'] = model_name\\n\",\n",
    "    \"    performance_summary.append(avg_metrics)\\n\",\n",
    "    \"\\n\",\n",
    "    \"performance_df = pd.DataFrame(performance_summary)\\n\",\n",
    "    \"performance_df = performance_df[['Model', 'Accuracy', 'Precision', 'Recall', 'F1', 'ROC-AUC']]\\n\",\n",
    "    \"print(\\\"\\\\nAverage Performance Metrics:\\\")\\n\",\n",
    "    \"display(performance_df)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 5. Performans Karşılaştırması ve ROC Eğrileri\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Prepare test set for final evaluation\\n\",\n",
    "    \"X_train, X_test, y_train, y_test = train_test_split(\\n\",\n",
    "    \"    X_scaled[selected_features], y, test_size=0.2, random_state=42, stratify=y\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Plot ROC curves for all models\\n\",\n",
    "    \"plt.figure(figsize=(10, 8))\\n\",\n",
    "    \"\\n\",\n",
    "    \"for model_name, data in model_results.items():\\n\",\n",
    "    \"    model = data['model']\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    if hasattr(model, \\\"predict_proba\\\"):\\n\",\n",
    "    \"        y_proba = model.predict_proba(X_test)[:, 1]\\n\",\n",
    "    \"    else:  # For SVM without probability\\n\",\n",
    "    \"        decision = model.decision_function(X_test)\\n\",\n",
    "    \"        y_proba = (decision - decision.min()) / (decision.max() - decision.min())\\n\",\n",
    "    \"        \\n\",\n",
    "    \"    fpr, tpr, _ = roc_curve(y_test, y_proba)\\n\",\n",
    "    \"    roc_auc = auc(fpr, tpr)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    plt.plot(fpr, tpr, lw=2, label=f'{model_name} (AUC = {roc_auc:.3f})')\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.plot([0, 1], [0, 1], color='gray', lw=1, linestyle='--')\\n\",\n",
    "    \"plt.xlim([0.0, 1.0])\\n\",\n",
    "    \"plt.ylim([0.0, 1.05])\\n\",\n",
    "    \"plt.xlabel('False Positive Rate')\\n\",\n",
    "    \"plt.ylabel('True Positive Rate')\\n\",\n",
    "    \"plt.title('ROC Curve Comparison')\\n\",\n",
    "    \"plt.legend(loc=\\\"lower right\\\")\\n\",\n",
    "    \"plt.grid(True)\\n\",\n",
    "    \"plt.savefig('../outputs/figures/roc_comparison.png', dpi=300)\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 6. Sonuçlar ve Yorum\\n\",\n",
    "    \"### En Başarılı Model Analizi\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Identify best model\\n\",\n",
    "    \"best_model_name = performance_df.sort_values('ROC-AUC', ascending=False).iloc[0]['Model']\\n\",\n",
    "    \"best_model = model_results[best_model_name]['model']\\n\",\n",
    "    \"best_metrics = performance_df[performance_df['Model'] == best_model_name].iloc[0]\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"Best Performing Model: {best_model_name}\\\")\\n\",\n",
    "    \"print(f\\\"ROC-AUC: {best_metrics['ROC-AUC']:.4f}\\\")\\n\",\n",
    "    \"print(f\\\"Accuracy: {best_metrics['Accuracy']:.4f}\\\")\\n\",\n",
    "    \"print(f\\\"F1 Score: {best_metrics['F1']:.4f}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Show best hyperparameters\\n\",\n",
    "    \"if hasattr(best_model, 'best_params_'):\\n\",\n",
    "    \"    print(\\\"\\\\nBest Hyperparameters:\\\")\\n\",\n",
    "    \"    display(pd.Series(best_model.best_params_).to_frame('Value'))\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 7. Proje Özeti ve Değerlendirme\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3 (ipykernel)\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.11.5\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11a887ea-d796-4ff1-a6b0-c5abb271ce66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: D:\\higgs_ml_project\n",
      "Python path: ['D:\\\\higgs_ml_project\\\\src', 'D:\\\\higgs_ml_project', 'C:\\\\Program Files\\\\Python311\\\\python311.zip', 'C:\\\\Program Files\\\\Python311\\\\DLLs', 'C:\\\\Program Files\\\\Python311\\\\Lib', 'C:\\\\Program Files\\\\Python311', 'D:\\\\higgs_ml_project\\\\higgs-env', '', 'D:\\\\higgs_ml_project\\\\higgs-env\\\\Lib\\\\site-packages', 'D:\\\\higgs_ml_project\\\\higgs-env\\\\Lib\\\\site-packages\\\\win32', 'D:\\\\higgs_ml_project\\\\higgs-env\\\\Lib\\\\site-packages\\\\win32\\\\lib', 'D:\\\\higgs_ml_project\\\\higgs-env\\\\Lib\\\\site-packages\\\\Pythonwin']\n"
     ]
    }
   ],
   "source": [
    "# Setup environment and paths\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Get the current working directory\n",
    "current_dir = Path.cwd()\n",
    "\n",
    "# Determine project root (assuming notebook is in notebooks/)\n",
    "project_root = current_dir.parent\n",
    "\n",
    "# Add project root to system path\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Add src directory to system path\n",
    "src_dir = project_root / 'src'\n",
    "if str(src_dir) not in sys.path:\n",
    "    sys.path.insert(0, str(src_dir))\n",
    "\n",
    "# Verify paths\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"Python path: {sys.path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "191fa0d6-1c78-4af4-8a19-f5ad4d7d0478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully imported evaluation functions\n",
      "Successfully imported preprocess_data\n",
      "All modules imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import dependencies\n",
    "import importlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def import_module(name, path):\n",
    "    \"\"\"Import a module from a specific path\"\"\"\n",
    "    spec = importlib.util.spec_from_file_location(name, path)\n",
    "    module = importlib.util.module_from_spec(spec)\n",
    "    spec.loader.exec_module(module)\n",
    "    return module\n",
    "# Import from our custom modules\n",
    "try:\n",
    "    from evaluation import (\n",
    "        generate_roc_comparison,\n",
    "        plot_anova_feature_importance,\n",
    "        plot_xgb_feature_importance\n",
    "    )\n",
    "    print(\"Successfully imported evaluation functions\")\n",
    "except ImportError:\n",
    "    print(\"Using fallback import for evaluation\")\n",
    "    evaluation_path = src_dir / 'evaluation.py'\n",
    "    evaluation = import_module(\"evaluation\", evaluation_path)\n",
    "    generate_roc_comparison = evaluation.generate_roc_comparison\n",
    "    plot_anova_feature_importance = evaluation.plot_anova_feature_importance\n",
    "    plot_xgb_feature_importance = evaluation.plot_xgb_feature_importance\n",
    "\n",
    "# Import preprocessing module\n",
    "try:\n",
    "    from preprocessing import preprocess_data\n",
    "    print(\"Successfully imported preprocess_data\")\n",
    "except ImportError:\n",
    "    print(\"Using fallback import for preprocessing\")\n",
    "    preprocessing_path = src_dir / 'preprocessing.py'\n",
    "    preprocessing = import_module(\"preprocessing\", preprocessing_path)\n",
    "    preprocess_data = preprocessing.preprocess_data\n",
    "\n",
    "print(\"All modules imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ec349d3-4020-40fb-b255-66b3e9d72ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preprocessing data...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/HIGGS.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 55\u001b[39m\n\u001b[32m     52\u001b[39m xgb_model = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (project_root / \u001b[33m'\u001b[39m\u001b[33moutputs\u001b[39m\u001b[33m'\u001b[39m / \u001b[33m'\u001b[39m\u001b[33mfeature_selector.pkl\u001b[39m\u001b[33m'\u001b[39m).exists():\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m     selector, xgb_model = \u001b[43mgenerate_missing_artifacts\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     57\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mFeature selector already exists\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 19\u001b[39m, in \u001b[36mgenerate_missing_artifacts\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Generate missing feature selector and XGBoost model\"\"\"\u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mLoading and preprocessing data...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m X, y = \u001b[43mpreprocess_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# 1. Create and save feature selector\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mCreating feature selector...\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\higgs_ml_project\\src\\preprocessing.py:30\u001b[39m, in \u001b[36mpreprocess_data\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpreprocess_data\u001b[39m():\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m     df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m./data/HIGGS.csv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m     X = df.iloc[:, \u001b[32m1\u001b[39m:].values\n\u001b[32m     32\u001b[39m     y = df.iloc[:, \u001b[32m0\u001b[39m].values\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\higgs_ml_project\\higgs-env\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\higgs_ml_project\\higgs-env\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\higgs_ml_project\\higgs-env\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\higgs_ml_project\\higgs-env\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\higgs_ml_project\\higgs-env\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: './data/HIGGS.csv'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from src.preprocessing import preprocess_data\n",
    "\n",
    "# Create output directories\n",
    "Path(project_root / 'outputs' / 'models').mkdir(parents=True, exist_ok=True)\n",
    "Path(project_root / 'outputs' / 'data').mkdir(parents=True, exist_ok=True)\n",
    "Path(project_root / 'outputs' / 'figures').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def generate_missing_artifacts():\n",
    "    \"\"\"Generate missing feature selector and XGBoost model\"\"\"\n",
    "    print(\"Loading and preprocessing data...\")\n",
    "    X, y = preprocess_data()\n",
    "    \n",
    "    # 1. Create and save feature selector\n",
    "    print(\"Creating feature selector...\")\n",
    "    selector = SelectKBest(score_func=f_classif, k=15)\n",
    "    selector.fit(X, y)\n",
    "    joblib.dump(selector, project_root / 'outputs' / 'feature_selector.pkl')\n",
    "    print(\"Feature selector saved\")\n",
    "    \n",
    "    # 2. Train and save simplified XGBoost model\n",
    "    print(\"Training simplified XGBoost model...\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "    \n",
    "    xgb_model = XGBClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=5,\n",
    "        learning_rate=0.1,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.9,\n",
    "        random_state=42,\n",
    "        use_label_encoder=False,\n",
    "        eval_metric='logloss'\n",
    "    )\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "    joblib.dump(xgb_model, project_root / 'outputs' / 'models' / 'XGBoost_simplified.pkl')\n",
    "    print(\"XGBoost model saved\")\n",
    "    \n",
    "    return selector, xgb_model\n",
    "\n",
    "# Generate artifacts if missing\n",
    "selector = None\n",
    "xgb_model = None\n",
    "\n",
    "if not (project_root / 'outputs' / 'feature_selector.pkl').exists():\n",
    "    selector, xgb_model = generate_missing_artifacts()\n",
    "else:\n",
    "    print(\"Feature selector already exists\")\n",
    "    selector = joblib.load(project_root / 'outputs' / 'feature_selector.pkl')\n",
    "\n",
    "if not (project_root / 'outputs' / 'models' / 'XGBoost_simplified.pkl').exists():\n",
    "    if xgb_model is None:\n",
    "        _, xgb_model = generate_missing_artifacts()\n",
    "else:\n",
    "    print(\"XGBoost model already exists\")\n",
    "    xgb_model = joblib.load(project_root / 'outputs' / 'models' / 'XGBoost_simplified.pkl')\n",
    "\n",
    "print(\"All artifacts are ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e837feac-d329-4a32-9185-de3fb98b4c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "try:\n",
    "    X_test = np.load(project_root / 'outputs' / 'data' / 'X_test.npy')\n",
    "    y_test = np.load(project_root / 'outputs' / 'data' / 'y_test.npy')\n",
    "    print(\"Loaded test data\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Test data not found. Creating...\")\n",
    "    X, y = preprocess_data()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "    np.save(project_root / 'outputs' / 'data' / 'X_test.npy', X_test)\n",
    "    np.save(project_root / 'outputs' / 'data' / 'y_test.npy', y_test)\n",
    "\n",
    "# Prepare model results dictionary\n",
    "model_results = {\n",
    "    'XGBoost': xgb_model\n",
    "}\n",
    "\n",
    "# Add other models if available\n",
    "for model_file in (project_root / 'outputs' / 'models').glob('*.pkl'):\n",
    "    model_name = model_file.stem\n",
    "    if model_name != 'XGBoost_simplified':\n",
    "        model_results[model_name] = joblib.load(model_file)\n",
    "\n",
    "# Generate ROC comparison\n",
    "generate_roc_comparison(\n",
    "    model_results,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    project_root / 'outputs' / 'figures' / 'roc_comparison.png'\n",
    ")\n",
    "\n",
    "# Generate ANOVA feature importance\n",
    "feature_names = [f'feature_{i}' for i in range(1, 29)]\n",
    "plot_anova_feature_importance(\n",
    "    selector,\n",
    "    feature_names,\n",
    "    project_root / 'outputs' / 'figures' / 'feature_importance.png'\n",
    ")\n",
    "\n",
    "# Generate XGBoost feature importance\n",
    "plot_xgb_feature_importance(\n",
    "    xgb_model,\n",
    "    feature_names,\n",
    "    project_root / 'outputs' / 'figures' / 'xgboost_feature_importance.png'\n",
    ")\n",
    "\n",
    "print(\"All visualizations generated successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad535dac-117f-48f0-a399-02baf17cf2c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9702d4-8488-4cb5-a91c-e72fc0b0d46b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "higgs-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
